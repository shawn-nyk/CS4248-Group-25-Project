{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1648884865630,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"mskzU0-gRRW0","outputId":"d49eca0a-274e-474c-b965-ac8014d6929c"},"outputs":[{"name":"stdout","output_type":"stream","text":["C:\\Users\\wongp\\OneDrive - National University of Singapore\n"]}],"source":["%cd \"OneDrive - National University of Singapore\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1648884867241,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"pwKcAVDmTT-j","outputId":"d75c33d7-f026-46ba-9b23-0c46d047f49f"},"outputs":[{"name":"stdout","output_type":"stream","text":["C:\\Users\\wongp\\OneDrive - National University of Singapore\\CS4248\\Project\\db\n"]}],"source":["%cd CS4248/Project/db/"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2823,"status":"ok","timestamp":1648884871513,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"gMXKnWRCq_lq"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from nltk.tokenize import word_tokenize\n","from collections import Counter\n","from keras.preprocessing import sequence\n","from sklearn.model_selection import train_test_split\n","import nltk\n","from nltk.stem import WordNetLemmatizer"]},{"cell_type":"markdown","metadata":{"id":"h7za2XhryELG"},"source":["Convert training data into csv file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzKToyYBtw28"},"outputs":[],"source":["import os\n","import pandas as pd\n","\n","pathNeg = \"train/neg\"\n","files = os.listdir(pathNeg)\n","data = []\n","for file in files:\n","  if os.path.isfile(os.path.join(pathNeg, file)):\n","    id = int(file.split(\"_\")[0])\n","    with open(os.path.join(pathNeg, file), encoding='utf8') as f:\n","      lines = f.read()\n","    data.append([id, lines, 0])\n","\n","sizeOfNeg = 12500\n","\n","pathPos = \"train/pos\"\n","files = os.listdir(pathPos)\n","for file in files:\n","  if os.path.isfile(os.path.join(pathPos, file)):\n","    id = int(file.split(\"_\")[0]) + sizeOfNeg\n","    with open(os.path.join(pathPos, file), encoding='utf8') as f:\n","      lines = f.read()\n","    data.append([id, lines, 1])\n","\n","\n","df = pd.DataFrame(data, columns = ['id', 'text', 'score']).set_index('id').sort_index()\n","df.to_csv('train.csv')"]},{"cell_type":"markdown","metadata":{"id":"9GNrBVLJyil9"},"source":["Convert testing data into csv file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82nRVA3QyiDK"},"outputs":[],"source":["pathNeg = \"test/neg\"\n","files = os.listdir(pathNeg)\n","data = []\n","for file in files:\n","  if os.path.isfile(os.path.join(pathNeg, file)):\n","    id = int(file.split(\"_\")[0])\n","    with open(os.path.join(pathNeg, file), encoding='utf8') as f:\n","      lines = f.read()\n","    data.append([id, lines, 0])\n","\n","sizeOfNeg = 12500\n","\n","pathPos = \"test/pos\"\n","files = os.listdir(pathPos)\n","for file in files:\n","  if os.path.isfile(os.path.join(pathPos, file)):\n","    id = int(file.split(\"_\")[0]) + sizeOfNeg\n","    with open(os.path.join(pathPos, file), encoding='utf8') as f:\n","      lines = f.read()\n","    data.append([id, lines, 1])\n","\n","\n","df = pd.DataFrame(data, columns = ['id', 'text', 'score']).set_index('id').sort_index()\n","df.to_csv('test.csv')"]},{"cell_type":"markdown","metadata":{"id":"uZpPn7ASz2g_"},"source":["convert vocab into csv file"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104,"status":"ok","timestamp":1647856717425,"user":{"displayName":"Peng Xiang Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12326358141916594350"},"user_tz":-480},"id":"owrxmb-kz1-O","outputId":"8bc1cc86-ec47-487e-9732-590d6bf6eef3"},"outputs":[{"name":"stdout","output_type":"stream","text":["                   vocab\n","0                    the\n","1                    and\n","2                      a\n","3                     of\n","4                     to\n","...                  ...\n","89522          copywrite\n","89523             artbox\n","89524          kinky-sex\n","89525           urrrghhh\n","89526  investigator-like\n","\n","[89527 rows x 1 columns]\n"]}],"source":["with open(\"imdb.vocab\", encoding='utf8') as f:\n","  vocab = []\n","  for line in f:\n","    vocab.append(line.rstrip())\n","\n","vocab_df = pd.DataFrame(vocab, columns=['vocab'])\n","print(vocab_df)\n","vocab_df.to_csv('vocab_given.csv', index=False)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1648884878056,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"CbTHvWVUAtsG"},"outputs":[],"source":["from nltk.tokenize import word_tokenize\n","\n","def tokenizeReview(review):\n","  review = review.replace('.', ' . ')\n","  tokens = word_tokenize(review.lower())\n","  return tokens"]},{"cell_type":"markdown","metadata":{"id":"j_4trjw6ZQWU"},"source":["Get vocab from training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A2HeD-pqZQNl"},"outputs":[],"source":["from collections import Counter\n","reviews = train_df['text'].tolist()\n","reviews = list(map(tokenizeReview, reviews))\n","reviews = [item for review in reviews for item in review]\n","vdict = Counter(reviews).most_common()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":105,"status":"ok","timestamp":1647866531973,"user":{"displayName":"Peng Xiang Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12326358141916594350"},"user_tz":-480},"id":"h2ENkTAedRPJ","outputId":"fdbae7ec-5562-4939-bf40-ef3f9371a5e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["              vocab\n","0               the\n","1                 .\n","2                 ,\n","3               and\n","4                 a\n","...             ...\n","99203    people-and\n","99204         padre\n","99205   unmatchable\n","99206  scenery-wise\n","99207  non-teenager\n","\n","[99208 rows x 1 columns]\n"]}],"source":["vocabs = []\n","for pair in vdict:\n","  vocabs.append(pair[0])\n","\n","vocab_df = pd.DataFrame(vocabs, columns=['vocab'])\n","vocab_df.to_csv('vocab.csv', index=False)\n","print(vocab_df)"]},{"cell_type":"markdown","metadata":{"id":"5jmqBO6nyORE"},"source":["Read training data and testing data from csv file (START HERE after initialization)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":601,"status":"ok","timestamp":1648884883492,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"jPmFOCWZyNtY","outputId":"3cb44d61-8f08-4898-8380-4ff77569a05a"},"outputs":[{"name":"stdout","output_type":"stream","text":["              vocab\n","0               the\n","1                 .\n","2                 ,\n","3               and\n","4                 a\n","...             ...\n","99203    people-and\n","99204         padre\n","99205   unmatchable\n","99206  scenery-wise\n","99207  non-teenager\n","\n","[99208 rows x 1 columns]\n"]}],"source":["train_df = pd.read_csv('train/train.csv')\n","test_df = pd.read_csv('test/test.csv')\n","vocab_df = pd.read_csv('vocab.csv')\n","print(vocab_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":871,"status":"ok","timestamp":1648884997179,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"NI0BwC5Y44j0","outputId":"dc839ab1-09e6-4dca-b1a0-f82edb9c9b43"},"outputs":[],"source":["vocab_dict = pd.Series(vocab_df.index + 1, index=vocab_df.vocab).to_dict()\n","print(vocab_dict)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1648884999650,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"gcwKHOAF7q0L"},"outputs":[],"source":["def convertToIndex(review):\n","  vec = []\n","  for word in review:\n","    if word in vocab_dict:\n","      vec.append(int(vocab_dict[word]))\n","    else:\n","      vec.append(0)\n","  return vec"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":29450,"status":"ok","timestamp":1648885031654,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"N76UYbaU8aqD"},"outputs":[],"source":["train_df['tokens'] = train_df['text'].apply(tokenizeReview)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1272,"status":"ok","timestamp":1648885033003,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"l9_yM1XLD7-4"},"outputs":[],"source":["train_df['vec'] = train_df['tokens'].apply(convertToIndex)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1648885099208,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"9Ng3zTgcD3DW","outputId":"ac8868a6-48a1-49f7-e715-7bba5069a1b9"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>score</th>\n","      <th>tokens</th>\n","      <th>vec</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Story of a man who has unnatural feelings for ...</td>\n","      <td>0</td>\n","      <td>[story, of, a, man, who, has, unnatural, feeli...</td>\n","      <td>[76, 6, 5, 142, 46, 56, 7518, 1387, 21, 5, 451...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Robert DeNiro plays the most unbelievably inte...</td>\n","      <td>0</td>\n","      <td>[robert, deniro, plays, the, most, unbelievabl...</td>\n","      <td>[649, 5006, 307, 1, 106, 3769, 1076, 9203, 6, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>I saw the capsule comment said \"great acting.\"...</td>\n","      <td>0</td>\n","      <td>[i, saw, the, capsule, comment, said, ``, grea...</td>\n","      <td>[15, 226, 1, 9586, 906, 311, 28, 102, 129, 2, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>If I had not read Pat Barker's 'Union Street' ...</td>\n","      <td>0</td>\n","      <td>[if, i, had, not, read, pat, barker, 's, 'unio...</td>\n","      <td>[57, 15, 78, 32, 338, 3189, 7720, 18, 34296, 8...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>This fanciful horror flick has Vincent Price p...</td>\n","      <td>0</td>\n","      <td>[this, fanciful, horror, flick, has, vincent, ...</td>\n","      <td>[16, 16016, 213, 512, 56, 3154, 1789, 397, 5, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24995</th>\n","      <td>24995</td>\n","      <td>What's Good About It: Some inventive and genui...</td>\n","      <td>1</td>\n","      <td>[what, 's, good, about, it, :, some, inventive...</td>\n","      <td>[60, 18, 62, 55, 13, 87, 61, 4388, 4, 2028, 93...</td>\n","    </tr>\n","    <tr>\n","      <th>24996</th>\n","      <td>24996</td>\n","      <td>For years we've been watching every horror fil...</td>\n","      <td>1</td>\n","      <td>[for, years, we, 've, been, watching, every, h...</td>\n","      <td>[21, 168, 82, 155, 93, 163, 188, 213, 25, 17, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24997</th>\n","      <td>24997</td>\n","      <td>If you haven't already seen this movie of Mary...</td>\n","      <td>1</td>\n","      <td>[if, you, have, n't, already, seen, this, movi...</td>\n","      <td>[57, 29, 37, 31, 466, 126, 16, 23, 6, 13586, 4...</td>\n","    </tr>\n","    <tr>\n","      <th>24998</th>\n","      <td>24998</td>\n","      <td>this movie is the best movie ever it has a lot...</td>\n","      <td>1</td>\n","      <td>[this, movie, is, the, best, movie, ever, it, ...</td>\n","      <td>[16, 23, 8, 1, 133, 23, 138, 13, 56, 5, 186, 6...</td>\n","    </tr>\n","    <tr>\n","      <th>24999</th>\n","      <td>24999</td>\n","      <td>I always feel strange and guilty saying it (be...</td>\n","      <td>1</td>\n","      <td>[i, always, feel, strange, and, guilty, saying...</td>\n","      <td>[15, 222, 248, 669, 4, 2490, 653, 13, 27, 101,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25000 rows × 5 columns</p>\n","</div>"],"text/plain":["          id                                               text  score  \\\n","0          0  Story of a man who has unnatural feelings for ...      0   \n","1          1  Robert DeNiro plays the most unbelievably inte...      0   \n","2          2  I saw the capsule comment said \"great acting.\"...      0   \n","3          3  If I had not read Pat Barker's 'Union Street' ...      0   \n","4          4  This fanciful horror flick has Vincent Price p...      0   \n","...      ...                                                ...    ...   \n","24995  24995  What's Good About It: Some inventive and genui...      1   \n","24996  24996  For years we've been watching every horror fil...      1   \n","24997  24997  If you haven't already seen this movie of Mary...      1   \n","24998  24998  this movie is the best movie ever it has a lot...      1   \n","24999  24999  I always feel strange and guilty saying it (be...      1   \n","\n","                                                  tokens  \\\n","0      [story, of, a, man, who, has, unnatural, feeli...   \n","1      [robert, deniro, plays, the, most, unbelievabl...   \n","2      [i, saw, the, capsule, comment, said, ``, grea...   \n","3      [if, i, had, not, read, pat, barker, 's, 'unio...   \n","4      [this, fanciful, horror, flick, has, vincent, ...   \n","...                                                  ...   \n","24995  [what, 's, good, about, it, :, some, inventive...   \n","24996  [for, years, we, 've, been, watching, every, h...   \n","24997  [if, you, have, n't, already, seen, this, movi...   \n","24998  [this, movie, is, the, best, movie, ever, it, ...   \n","24999  [i, always, feel, strange, and, guilty, saying...   \n","\n","                                                     vec  \n","0      [76, 6, 5, 142, 46, 56, 7518, 1387, 21, 5, 451...  \n","1      [649, 5006, 307, 1, 106, 3769, 1076, 9203, 6, ...  \n","2      [15, 226, 1, 9586, 906, 311, 28, 102, 129, 2, ...  \n","3      [57, 15, 78, 32, 338, 3189, 7720, 18, 34296, 8...  \n","4      [16, 16016, 213, 512, 56, 3154, 1789, 397, 5, ...  \n","...                                                  ...  \n","24995  [60, 18, 62, 55, 13, 87, 61, 4388, 4, 2028, 93...  \n","24996  [21, 168, 82, 155, 93, 163, 188, 213, 25, 17, ...  \n","24997  [57, 29, 37, 31, 466, 126, 16, 23, 6, 13586, 4...  \n","24998  [16, 23, 8, 1, 133, 23, 138, 13, 56, 5, 186, 6...  \n","24999  [15, 222, 248, 669, 4, 2490, 653, 13, 27, 101,...  \n","\n","[25000 rows x 5 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1648574032374,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"0Y3---BVrjuB","outputId":"0f88f257-baa0-4dc3-e744-4c2cf69ccb7c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Maximum review length: 2820\n","Minimum review length: 11\n"]}],"source":["print('Maximum review length: {}'.format(\n","len(max((train_df['tokens']), key=len))))\n","print('Minimum review length: {}'.format(\n","len(min((train_df['tokens']), key=len))))"]},{"cell_type":"markdown","metadata":{"id":"y64V7tEl3FzS"},"source":["Lemmatizer"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1648885105877,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"vpNiF_6C3FC5","outputId":"3fc9f72e-c36a-4d9c-9d26-74b763c6dc3f"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\wongp\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     C:\\Users\\wongp\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}],"source":["wordnet_lemmatizer = WordNetLemmatizer()\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","\n","def lemmatizer(reviewTokens):\n","  punctuations=\"?:!.,;\"\n","  for word in reviewTokens:\n","    if word in punctuations:\n","      reviewTokens.remove(word)\n","  reviewLemm = []\n","  for word in reviewTokens:\n","    newWord = wordnet_lemmatizer.lemmatize(word, pos=\"v\")\n","    reviewLemm.append(newWord)\n","\n","  return reviewLemm\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":17743,"status":"ok","timestamp":1648885127377,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"faP-fgJ24j-D"},"outputs":[],"source":["train_df['lemmTokens'] = train_df['tokens'].apply(lemmatizer)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1648885129054,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"6cYzKMxd487-","outputId":"b6d1caf3-4c2f-41ef-df14-e1ea71e5b038"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>score</th>\n","      <th>tokens</th>\n","      <th>vec</th>\n","      <th>lemmTokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Story of a man who has unnatural feelings for ...</td>\n","      <td>0</td>\n","      <td>[story, of, a, man, who, has, unnatural, feeli...</td>\n","      <td>[76, 6, 5, 142, 46, 56, 7518, 1387, 21, 5, 451...</td>\n","      <td>[story, of, a, man, who, have, unnatural, feel...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Robert DeNiro plays the most unbelievably inte...</td>\n","      <td>0</td>\n","      <td>[robert, deniro, plays, the, most, unbelievabl...</td>\n","      <td>[649, 5006, 307, 1, 106, 3769, 1076, 9203, 6, ...</td>\n","      <td>[robert, deniro, play, the, most, unbelievably...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>I saw the capsule comment said \"great acting.\"...</td>\n","      <td>0</td>\n","      <td>[i, saw, the, capsule, comment, said, ``, grea...</td>\n","      <td>[15, 226, 1, 9586, 906, 311, 28, 102, 129, 2, ...</td>\n","      <td>[i, saw, the, capsule, comment, say, ``, great...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>If I had not read Pat Barker's 'Union Street' ...</td>\n","      <td>0</td>\n","      <td>[if, i, had, not, read, pat, barker, 's, 'unio...</td>\n","      <td>[57, 15, 78, 32, 338, 3189, 7720, 18, 34296, 8...</td>\n","      <td>[if, i, have, not, read, pat, barker, 's, 'uni...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>This fanciful horror flick has Vincent Price p...</td>\n","      <td>0</td>\n","      <td>[this, fanciful, horror, flick, has, vincent, ...</td>\n","      <td>[16, 16016, 213, 512, 56, 3154, 1789, 397, 5, ...</td>\n","      <td>[this, fanciful, horror, flick, have, vincent,...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24995</th>\n","      <td>24995</td>\n","      <td>What's Good About It: Some inventive and genui...</td>\n","      <td>1</td>\n","      <td>[what, 's, good, about, it, some, inventive, a...</td>\n","      <td>[60, 18, 62, 55, 13, 87, 61, 4388, 4, 2028, 93...</td>\n","      <td>[what, 's, good, about, it, some, inventive, a...</td>\n","    </tr>\n","    <tr>\n","      <th>24996</th>\n","      <td>24996</td>\n","      <td>For years we've been watching every horror fil...</td>\n","      <td>1</td>\n","      <td>[for, years, we, 've, been, watching, every, h...</td>\n","      <td>[21, 168, 82, 155, 93, 163, 188, 213, 25, 17, ...</td>\n","      <td>[for, years, we, 've, be, watch, every, horror...</td>\n","    </tr>\n","    <tr>\n","      <th>24997</th>\n","      <td>24997</td>\n","      <td>If you haven't already seen this movie of Mary...</td>\n","      <td>1</td>\n","      <td>[if, you, have, n't, already, seen, this, movi...</td>\n","      <td>[57, 29, 37, 31, 466, 126, 16, 23, 6, 13586, 4...</td>\n","      <td>[if, you, have, n't, already, see, this, movie...</td>\n","    </tr>\n","    <tr>\n","      <th>24998</th>\n","      <td>24998</td>\n","      <td>this movie is the best movie ever it has a lot...</td>\n","      <td>1</td>\n","      <td>[this, movie, is, the, best, movie, ever, it, ...</td>\n","      <td>[16, 23, 8, 1, 133, 23, 138, 13, 56, 5, 186, 6...</td>\n","      <td>[this, movie, be, the, best, movie, ever, it, ...</td>\n","    </tr>\n","    <tr>\n","      <th>24999</th>\n","      <td>24999</td>\n","      <td>I always feel strange and guilty saying it (be...</td>\n","      <td>1</td>\n","      <td>[i, always, feel, strange, and, guilty, saying...</td>\n","      <td>[15, 222, 248, 669, 4, 2490, 653, 13, 27, 101,...</td>\n","      <td>[i, always, feel, strange, and, guilty, say, i...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25000 rows × 6 columns</p>\n","</div>"],"text/plain":["          id                                               text  score  \\\n","0          0  Story of a man who has unnatural feelings for ...      0   \n","1          1  Robert DeNiro plays the most unbelievably inte...      0   \n","2          2  I saw the capsule comment said \"great acting.\"...      0   \n","3          3  If I had not read Pat Barker's 'Union Street' ...      0   \n","4          4  This fanciful horror flick has Vincent Price p...      0   \n","...      ...                                                ...    ...   \n","24995  24995  What's Good About It: Some inventive and genui...      1   \n","24996  24996  For years we've been watching every horror fil...      1   \n","24997  24997  If you haven't already seen this movie of Mary...      1   \n","24998  24998  this movie is the best movie ever it has a lot...      1   \n","24999  24999  I always feel strange and guilty saying it (be...      1   \n","\n","                                                  tokens  \\\n","0      [story, of, a, man, who, has, unnatural, feeli...   \n","1      [robert, deniro, plays, the, most, unbelievabl...   \n","2      [i, saw, the, capsule, comment, said, ``, grea...   \n","3      [if, i, had, not, read, pat, barker, 's, 'unio...   \n","4      [this, fanciful, horror, flick, has, vincent, ...   \n","...                                                  ...   \n","24995  [what, 's, good, about, it, some, inventive, a...   \n","24996  [for, years, we, 've, been, watching, every, h...   \n","24997  [if, you, have, n't, already, seen, this, movi...   \n","24998  [this, movie, is, the, best, movie, ever, it, ...   \n","24999  [i, always, feel, strange, and, guilty, saying...   \n","\n","                                                     vec  \\\n","0      [76, 6, 5, 142, 46, 56, 7518, 1387, 21, 5, 451...   \n","1      [649, 5006, 307, 1, 106, 3769, 1076, 9203, 6, ...   \n","2      [15, 226, 1, 9586, 906, 311, 28, 102, 129, 2, ...   \n","3      [57, 15, 78, 32, 338, 3189, 7720, 18, 34296, 8...   \n","4      [16, 16016, 213, 512, 56, 3154, 1789, 397, 5, ...   \n","...                                                  ...   \n","24995  [60, 18, 62, 55, 13, 87, 61, 4388, 4, 2028, 93...   \n","24996  [21, 168, 82, 155, 93, 163, 188, 213, 25, 17, ...   \n","24997  [57, 29, 37, 31, 466, 126, 16, 23, 6, 13586, 4...   \n","24998  [16, 23, 8, 1, 133, 23, 138, 13, 56, 5, 186, 6...   \n","24999  [15, 222, 248, 669, 4, 2490, 653, 13, 27, 101,...   \n","\n","                                              lemmTokens  \n","0      [story, of, a, man, who, have, unnatural, feel...  \n","1      [robert, deniro, play, the, most, unbelievably...  \n","2      [i, saw, the, capsule, comment, say, ``, great...  \n","3      [if, i, have, not, read, pat, barker, 's, 'uni...  \n","4      [this, fanciful, horror, flick, have, vincent,...  \n","...                                                  ...  \n","24995  [what, 's, good, about, it, some, inventive, a...  \n","24996  [for, years, we, 've, be, watch, every, horror...  \n","24997  [if, you, have, n't, already, see, this, movie...  \n","24998  [this, movie, be, the, best, movie, ever, it, ...  \n","24999  [i, always, feel, strange, and, guilty, say, i...  \n","\n","[25000 rows x 6 columns]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1050,"status":"ok","timestamp":1648885141693,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"6drZ0J1B5s9B","outputId":"920a8e1a-4407-4751-ce0c-31992a8adf50"},"outputs":[],"source":["from collections import Counter\n","reviewsLem = train_df['lemmTokens'].tolist()\n","# reviewsLem = list(map(tokenizeReview, reviewsLem))\n","reviewsLem = [item for review in reviewsLem for item in review]\n","vdictLem = Counter(reviewsLem).most_common()\n","#print(vdictLem)\n","\n","vdictLemToIdx = {}\n","idx = 1\n","for pair in vdictLem:\n","  vdictLemToIdx[pair[0]] = idx\n","  idx = idx + 1\n","print(vdictLemToIdx)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1648885145723,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"6_VzzEt37mDe"},"outputs":[],"source":["def convertToIndex(review):\n","  vec = []\n","  for word in review:\n","    if word in vdictLemToIdx:\n","      vec.append(int(vdictLemToIdx[word]))\n","    else:\n","      vec.append(0)\n","  return vec"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":907,"status":"ok","timestamp":1648885149261,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"-fmLdAiA7ZBm"},"outputs":[],"source":["train_df['vecLem'] = train_df['lemmTokens'].apply(convertToIndex)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1648885152137,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"gfb3E8T873uU","outputId":"4a9d8a3b-8be9-491f-bfe7-753837afa934"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>score</th>\n","      <th>tokens</th>\n","      <th>vec</th>\n","      <th>lemmTokens</th>\n","      <th>vecLem</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Story of a man who has unnatural feelings for ...</td>\n","      <td>0</td>\n","      <td>[story, of, a, man, who, has, unnatural, feeli...</td>\n","      <td>[76, 6, 5, 142, 46, 56, 7518, 1387, 21, 5, 451...</td>\n","      <td>[story, of, a, man, who, have, unnatural, feel...</td>\n","      <td>[76, 5, 4, 135, 43, 17, 6484, 145, 20, 4, 2990...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Robert DeNiro plays the most unbelievably inte...</td>\n","      <td>0</td>\n","      <td>[robert, deniro, plays, the, most, unbelievabl...</td>\n","      <td>[649, 5006, 307, 1, 106, 3769, 1076, 9203, 6, ...</td>\n","      <td>[robert, deniro, play, the, most, unbelievably...</td>\n","      <td>[654, 4427, 107, 1, 104, 3383, 1052, 7869, 5, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>I saw the capsule comment said \"great acting.\"...</td>\n","      <td>0</td>\n","      <td>[i, saw, the, capsule, comment, said, ``, grea...</td>\n","      <td>[15, 226, 1, 9586, 906, 311, 28, 102, 129, 2, ...</td>\n","      <td>[i, saw, the, capsule, comment, say, ``, great...</td>\n","      <td>[13, 228, 1, 8022, 417, 88, 27, 99, 106, 27, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>If I had not read Pat Barker's 'Union Street' ...</td>\n","      <td>0</td>\n","      <td>[if, i, had, not, read, pat, barker, 's, 'unio...</td>\n","      <td>[57, 15, 78, 32, 338, 3189, 7720, 18, 34296, 8...</td>\n","      <td>[if, i, have, not, read, pat, barker, 's, 'uni...</td>\n","      <td>[53, 13, 17, 31, 266, 2761, 6646, 16, 28419, 8...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>This fanciful horror flick has Vincent Price p...</td>\n","      <td>0</td>\n","      <td>[this, fanciful, horror, flick, has, vincent, ...</td>\n","      <td>[16, 16016, 213, 512, 56, 3154, 1789, 397, 5, ...</td>\n","      <td>[this, fanciful, horror, flick, have, vincent,...</td>\n","      <td>[14, 13459, 215, 420, 17, 2872, 1554, 107, 4, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24995</th>\n","      <td>24995</td>\n","      <td>What's Good About It: Some inventive and genui...</td>\n","      <td>1</td>\n","      <td>[what, 's, good, about, it, some, inventive, a...</td>\n","      <td>[60, 18, 62, 55, 13, 87, 61, 4388, 4, 2028, 93...</td>\n","      <td>[what, 's, good, about, it, some, inventive, a...</td>\n","      <td>[56, 16, 59, 52, 11, 57, 3881, 3, 1876, 925, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>24996</th>\n","      <td>24996</td>\n","      <td>For years we've been watching every horror fil...</td>\n","      <td>1</td>\n","      <td>[for, years, we, 've, been, watching, every, h...</td>\n","      <td>[21, 168, 82, 155, 93, 163, 188, 213, 25, 17, ...</td>\n","      <td>[for, years, we, 've, be, watch, every, horror...</td>\n","      <td>[20, 164, 79, 149, 2, 65, 186, 215, 18, 15, 10...</td>\n","    </tr>\n","    <tr>\n","      <th>24997</th>\n","      <td>24997</td>\n","      <td>If you haven't already seen this movie of Mary...</td>\n","      <td>1</td>\n","      <td>[if, you, have, n't, already, seen, this, movi...</td>\n","      <td>[57, 29, 37, 31, 466, 126, 16, 23, 6, 13586, 4...</td>\n","      <td>[if, you, have, n't, already, see, this, movie...</td>\n","      <td>[53, 28, 17, 30, 480, 44, 14, 22, 5, 11464, 3,...</td>\n","    </tr>\n","    <tr>\n","      <th>24998</th>\n","      <td>24998</td>\n","      <td>this movie is the best movie ever it has a lot...</td>\n","      <td>1</td>\n","      <td>[this, movie, is, the, best, movie, ever, it, ...</td>\n","      <td>[16, 23, 8, 1, 133, 23, 138, 13, 56, 5, 186, 6...</td>\n","      <td>[this, movie, be, the, best, movie, ever, it, ...</td>\n","      <td>[14, 22, 2, 1, 129, 22, 132, 11, 17, 4, 156, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>24999</th>\n","      <td>24999</td>\n","      <td>I always feel strange and guilty saying it (be...</td>\n","      <td>1</td>\n","      <td>[i, always, feel, strange, and, guilty, saying...</td>\n","      <td>[15, 222, 248, 669, 4, 2490, 653, 13, 27, 101,...</td>\n","      <td>[i, always, feel, strange, and, guilty, say, i...</td>\n","      <td>[13, 227, 145, 669, 3, 2277, 88, 11, 26, 98, 1...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25000 rows × 7 columns</p>\n","</div>"],"text/plain":["          id                                               text  score  \\\n","0          0  Story of a man who has unnatural feelings for ...      0   \n","1          1  Robert DeNiro plays the most unbelievably inte...      0   \n","2          2  I saw the capsule comment said \"great acting.\"...      0   \n","3          3  If I had not read Pat Barker's 'Union Street' ...      0   \n","4          4  This fanciful horror flick has Vincent Price p...      0   \n","...      ...                                                ...    ...   \n","24995  24995  What's Good About It: Some inventive and genui...      1   \n","24996  24996  For years we've been watching every horror fil...      1   \n","24997  24997  If you haven't already seen this movie of Mary...      1   \n","24998  24998  this movie is the best movie ever it has a lot...      1   \n","24999  24999  I always feel strange and guilty saying it (be...      1   \n","\n","                                                  tokens  \\\n","0      [story, of, a, man, who, has, unnatural, feeli...   \n","1      [robert, deniro, plays, the, most, unbelievabl...   \n","2      [i, saw, the, capsule, comment, said, ``, grea...   \n","3      [if, i, had, not, read, pat, barker, 's, 'unio...   \n","4      [this, fanciful, horror, flick, has, vincent, ...   \n","...                                                  ...   \n","24995  [what, 's, good, about, it, some, inventive, a...   \n","24996  [for, years, we, 've, been, watching, every, h...   \n","24997  [if, you, have, n't, already, seen, this, movi...   \n","24998  [this, movie, is, the, best, movie, ever, it, ...   \n","24999  [i, always, feel, strange, and, guilty, saying...   \n","\n","                                                     vec  \\\n","0      [76, 6, 5, 142, 46, 56, 7518, 1387, 21, 5, 451...   \n","1      [649, 5006, 307, 1, 106, 3769, 1076, 9203, 6, ...   \n","2      [15, 226, 1, 9586, 906, 311, 28, 102, 129, 2, ...   \n","3      [57, 15, 78, 32, 338, 3189, 7720, 18, 34296, 8...   \n","4      [16, 16016, 213, 512, 56, 3154, 1789, 397, 5, ...   \n","...                                                  ...   \n","24995  [60, 18, 62, 55, 13, 87, 61, 4388, 4, 2028, 93...   \n","24996  [21, 168, 82, 155, 93, 163, 188, 213, 25, 17, ...   \n","24997  [57, 29, 37, 31, 466, 126, 16, 23, 6, 13586, 4...   \n","24998  [16, 23, 8, 1, 133, 23, 138, 13, 56, 5, 186, 6...   \n","24999  [15, 222, 248, 669, 4, 2490, 653, 13, 27, 101,...   \n","\n","                                              lemmTokens  \\\n","0      [story, of, a, man, who, have, unnatural, feel...   \n","1      [robert, deniro, play, the, most, unbelievably...   \n","2      [i, saw, the, capsule, comment, say, ``, great...   \n","3      [if, i, have, not, read, pat, barker, 's, 'uni...   \n","4      [this, fanciful, horror, flick, have, vincent,...   \n","...                                                  ...   \n","24995  [what, 's, good, about, it, some, inventive, a...   \n","24996  [for, years, we, 've, be, watch, every, horror...   \n","24997  [if, you, have, n't, already, see, this, movie...   \n","24998  [this, movie, be, the, best, movie, ever, it, ...   \n","24999  [i, always, feel, strange, and, guilty, say, i...   \n","\n","                                                  vecLem  \n","0      [76, 5, 4, 135, 43, 17, 6484, 145, 20, 4, 2990...  \n","1      [654, 4427, 107, 1, 104, 3383, 1052, 7869, 5, ...  \n","2      [13, 228, 1, 8022, 417, 88, 27, 99, 106, 27, 1...  \n","3      [53, 13, 17, 31, 266, 2761, 6646, 16, 28419, 8...  \n","4      [14, 13459, 215, 420, 17, 2872, 1554, 107, 4, ...  \n","...                                                  ...  \n","24995  [56, 16, 59, 52, 11, 57, 3881, 3, 1876, 925, 1...  \n","24996  [20, 164, 79, 149, 2, 65, 186, 215, 18, 15, 10...  \n","24997  [53, 28, 17, 30, 480, 44, 14, 22, 5, 11464, 3,...  \n","24998  [14, 22, 2, 1, 129, 22, 132, 11, 17, 4, 156, 5...  \n","24999  [13, 227, 145, 669, 3, 2277, 88, 11, 26, 98, 1...  \n","\n","[25000 rows x 7 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_df"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":945,"status":"ok","timestamp":1648885157007,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"HbysWXb0ggT-"},"outputs":[],"source":["max_words = 500\n","dataset = sequence.pad_sequences(train_df['vecLem'], maxlen=max_words)\n","y = train_df['score']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r5QDjV3MsHEd"},"outputs":[],"source":["X_train, X_val, y_train, y_val = train_test_split(dataset, y, test_size=0.3, stratify=y, random_state = 42)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13467,"status":"ok","timestamp":1648885174252,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"-JUc-Q-6sud0","outputId":"8cc42426-b511-4a3e-ff77-9f16884f2090"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 0.079084 -0.81504   1.7901    0.91653   0.10797  -0.55628  -0.84427\n"," -1.4951    0.13418   0.63627   0.35146   0.25813  -0.55029   0.51056\n","  0.37409   0.12092  -1.6166    0.83653   0.14202  -0.52348   0.73453\n","  0.12207  -0.49079   0.32533   0.45306  -1.585    -0.63848  -1.0053\n","  0.10454  -0.42984   3.181    -0.62187   0.16819  -1.0139    0.064058\n","  0.57844  -0.4556    0.73783   0.37203  -0.57722   0.66441   0.055129\n","  0.037891  1.3275    0.30991   0.50697   1.2357    0.1274   -0.11434\n","  0.20709 ]\n"]}],"source":["from gensim.models import Word2Vec\n","import gensim.downloader as api\n","\n","v2w_model = api.load('glove-wiki-gigaword-50')\n","print(v2w_model['computer'])"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":124,"status":"ok","timestamp":1648885176650,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"21k7hezWrn1g"},"outputs":[],"source":["embedding_dim = 100\n","vocab_len = len(vdictLemToIdx) + 1\n","embed_vector_len = v2w_model['computer'].shape[0]\n","emb_matrix = np.zeros((vocab_len, embed_vector_len))\n","\n","for word, i in vdictLemToIdx.items():\n","  if word in v2w_model:\n","    embedding_vector = v2w_model.get_vector(word)\n","    emb_matrix[i] = embedding_vector\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1648885181908,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"8O0AlL8ZuoKp","outputId":"b2503387-c151-4e75-9088-3b3c0df2bdbc"},"outputs":[{"data":{"text/plain":["array([ 4.18000013e-01,  2.49679998e-01, -4.12420005e-01,  1.21699996e-01,\n","        3.45270008e-01, -4.44569997e-02, -4.96879995e-01, -1.78619996e-01,\n","       -6.60229998e-04, -6.56599998e-01,  2.78430015e-01, -1.47670001e-01,\n","       -5.56770027e-01,  1.46579996e-01, -9.50950012e-03,  1.16579998e-02,\n","        1.02040000e-01, -1.27920002e-01, -8.44299972e-01, -1.21809997e-01,\n","       -1.68009996e-02, -3.32789987e-01, -1.55200005e-01, -2.31309995e-01,\n","       -1.91809997e-01, -1.88230002e+00, -7.67459989e-01,  9.90509987e-02,\n","       -4.21249986e-01, -1.95260003e-01,  4.00710011e+00, -1.85939997e-01,\n","       -5.22870004e-01, -3.16810012e-01,  5.92130003e-04,  7.44489999e-03,\n","        1.77780002e-01, -1.58969998e-01,  1.20409997e-02, -5.42230010e-02,\n","       -2.98709989e-01, -1.57490000e-01, -3.47579986e-01, -4.56370004e-02,\n","       -4.42510009e-01,  1.87849998e-01,  2.78489990e-03, -1.84110001e-01,\n","       -1.15139998e-01, -7.85809994e-01])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["emb_matrix[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1648646100395,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"LkafaPRDuZqy","outputId":"c525b5d0-fbe2-4037-8a28-03a25ca923af"},"outputs":[{"name":"stdout","output_type":"stream","text":["88182\n"]}],"source":["print(vocab_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":446,"status":"ok","timestamp":1648646107813,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"grqoO75avHov","outputId":"12aab996-12d0-4517-f524-9b030b82ff60"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 500, 50)           4409100   \n","                                                                 \n"," gru (GRU)                   (None, 500, 50)           15300     \n","                                                                 \n"," dropout (Dropout)           (None, 500, 50)           0         \n","                                                                 \n"," gru_1 (GRU)                 (None, 50)                15300     \n","                                                                 \n"," dense (Dense)               (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 4,439,751\n","Trainable params: 30,651\n","Non-trainable params: 4,409,100\n","_________________________________________________________________\n","None\n"]}],"source":["from keras import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n","\n","embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=max_words, weights=[emb_matrix], trainable=False)\n","\n","embedding_size=32\n","model=Sequential()\n","model.add(embedding_layer)\n","model.add(GRU(units=50, return_sequences = True, input_shape=(X_train.shape[1],1), activation='tanh'))\n","#model.add(LSTM(100))\n","model.add(Dropout(0.6))\n","model.add(GRU(units=50, input_shape=(X_train.shape[1],1), activation='tanh'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', \n","             optimizer='adam', \n","             metrics=['accuracy'])\n","print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":641974,"status":"ok","timestamp":1648646780128,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"NfwabNuuwHTj","outputId":"d108455f-3a95-47d5-fe39-7275e1ba14db"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","547/547 [==============================] - 131s 235ms/step - loss: 0.6336 - accuracy: 0.6287\n","Epoch 2/5\n","547/547 [==============================] - 128s 234ms/step - loss: 0.4394 - accuracy: 0.7997\n","Epoch 3/5\n","547/547 [==============================] - 129s 237ms/step - loss: 0.3768 - accuracy: 0.8320\n","Epoch 4/5\n","547/547 [==============================] - 125s 228ms/step - loss: 0.3498 - accuracy: 0.8476\n","Epoch 5/5\n","547/547 [==============================] - 129s 235ms/step - loss: 0.3359 - accuracy: 0.8551\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2637035a460>"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["batch_size=32\n","model.fit(X_train, y_train, epochs = 5, batch_size=batch_size, verbose = 'auto')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12777,"status":"ok","timestamp":1648646792972,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"Dcgz9u2zwNr0","outputId":"fc895957-d79a-4c51-c3a9-4b94d136a792"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.8587999939918518\n"]}],"source":["scores = model.evaluate(X_val, y_val, verbose=0)\n","print('Test accuracy:', scores[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2342,"status":"ok","timestamp":1648026740222,"user":{"displayName":"Peng Xiang Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12326358141916594350"},"user_tz":-480},"id":"4C4chhqDzE6h","outputId":"465f17b0-1c18-47b8-c2f1-3c306c0c1cdd"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: basic_gru_model\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: basic_gru_model\\assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000023D12CBCC70> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]}],"source":["model.save('basic_model')"]},{"cell_type":"markdown","metadata":{"id":"t418TxNQ0dFK"},"source":["**Without Glove word embedding**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":156,"status":"ok","timestamp":1648646844929,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"uLCv1cP8zn0P","outputId":"bfb493b0-47aa-4093-c164-c697bcd6577c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 500, 32)           2821824   \n","                                                                 \n"," gru_2 (GRU)                 (None, 50)                12600     \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 2,834,475\n","Trainable params: 2,834,475\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["from keras import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n","embedding_size=32\n","model=Sequential()\n","model.add(Embedding(vocab_len, embedding_size, input_length=max_words))\n","model.add(GRU(units=50, input_shape=(X_train.shape[1],1), activation='tanh'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', \n","             optimizer='adam', \n","             metrics=['accuracy'])\n","print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":366193,"status":"ok","timestamp":1648647214021,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"sHrlPHPEzpuT","outputId":"68126299-c882-4b51-be82-93a23227d847"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","547/547 [==============================] - 73s 131ms/step - loss: 0.4788 - accuracy: 0.7517\n","Epoch 2/5\n","547/547 [==============================] - 74s 135ms/step - loss: 0.2361 - accuracy: 0.9089\n","Epoch 3/5\n","547/547 [==============================] - 73s 134ms/step - loss: 0.1233 - accuracy: 0.9581\n","Epoch 4/5\n","547/547 [==============================] - 73s 133ms/step - loss: 0.0666 - accuracy: 0.9804\n","Epoch 5/5\n","547/547 [==============================] - 73s 133ms/step - loss: 0.0372 - accuracy: 0.9881\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2639054cc40>"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["batch_size=32\n","model.fit(X_train, y_train, epochs = 5, batch_size=batch_size, verbose = 'auto')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6931,"status":"ok","timestamp":1648647220954,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"Mb2Cjdo1zrnV","outputId":"6d931b9d-9837-4448-8b24-c46a687e717b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.8755999803543091\n"]}],"source":["scores = model.evaluate(X_val, y_val, verbose=0)\n","print('Test accuracy:', scores[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":708708,"status":"ok","timestamp":1648648465310,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"LLotATq0CUmy","outputId":"3ec77703-75d8-418e-ea4c-2b203c2b45b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, 500, 32)           2821824   \n","                                                                 \n"," gru_3 (GRU)                 (None, 500, 50)           12600     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 500, 50)           0         \n","                                                                 \n"," gru_4 (GRU)                 (None, 50)                15300     \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 2,849,775\n","Trainable params: 2,849,775\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/5\n","547/547 [==============================] - 140s 252ms/step - loss: 0.4719 - accuracy: 0.7647\n","Epoch 2/5\n","547/547 [==============================] - 140s 256ms/step - loss: 0.2092 - accuracy: 0.9214\n","Epoch 3/5\n","547/547 [==============================] - 138s 252ms/step - loss: 0.1047 - accuracy: 0.9647\n","Epoch 4/5\n","547/547 [==============================] - 138s 253ms/step - loss: 0.0653 - accuracy: 0.9794\n","Epoch 5/5\n","547/547 [==============================] - 139s 255ms/step - loss: 0.0461 - accuracy: 0.9856\n","Test accuracy: 0.8712000250816345\n"]}],"source":["from keras import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n","embedding_size=32\n","model=Sequential()\n","model.add(Embedding(vocab_len, embedding_size, input_length=max_words))\n","model.add(GRU(units=50, return_sequences = True, input_shape=(X_train.shape[1],1), activation='tanh'))\n","#model.add(LSTM(100))\n","model.add(Dropout(0.6))\n","model.add(GRU(units=50, input_shape=(X_train.shape[1],1), activation='tanh'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', \n","             optimizer='adam', \n","             metrics=['accuracy'])\n","print(model.summary())\n","\n","batch_size=32\n","model.fit(X_train, y_train, epochs = 5, batch_size=batch_size, verbose = 'auto')\n","\n","scores = model.evaluate(X_val, y_val, verbose=0)\n","print('Test accuracy:', scores[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":729997,"status":"ok","timestamp":1648649220733,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"AkfqvZnOCWzH","outputId":"48d3151e-5425-4b7e-f722-b12f303eaedf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_3 (Embedding)     (None, 500, 50)           4409100   \n","                                                                 \n"," gru_5 (GRU)                 (None, 500, 50)           15300     \n","                                                                 \n"," dropout_2 (Dropout)         (None, 500, 50)           0         \n","                                                                 \n"," gru_6 (GRU)                 (None, 50)                15300     \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 4,439,751\n","Trainable params: 4,439,751\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/5\n","547/547 [==============================] - 147s 266ms/step - loss: 0.5353 - accuracy: 0.7108\n","Epoch 2/5\n","547/547 [==============================] - 142s 260ms/step - loss: 0.2725 - accuracy: 0.8903\n","Epoch 3/5\n","547/547 [==============================] - 143s 261ms/step - loss: 0.1534 - accuracy: 0.9467\n","Epoch 4/5\n","547/547 [==============================] - 142s 260ms/step - loss: 0.0703 - accuracy: 0.9781\n","Epoch 5/5\n","547/547 [==============================] - 142s 260ms/step - loss: 0.0293 - accuracy: 0.9924\n","Test accuracy: 0.8790666460990906\n"]}],"source":["from keras import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n","\n","embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=max_words, weights=[emb_matrix], trainable=True)\n","\n","embedding_size=32\n","model=Sequential()\n","model.add(embedding_layer)\n","model.add(GRU(units=50, return_sequences = True, input_shape=(X_train.shape[1],1), activation='tanh'))\n","#model.add(LSTM(100))\n","model.add(Dropout(0.6))\n","model.add(GRU(units=50, input_shape=(X_train.shape[1],1), activation='tanh'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', \n","             optimizer='adam', \n","             metrics=['accuracy'])\n","print(model.summary())\n","\n","batch_size=32\n","model.fit(X_train, y_train, epochs = 5, batch_size=batch_size, verbose = 'auto')\n","\n","scores = model.evaluate(X_val, y_val, verbose=0)\n","print('Test accuracy:', scores[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":392370,"status":"ok","timestamp":1648649622388,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"-fkR-1OkFBq6","outputId":"f5d33a1c-b261-446c-dbf1-85c4efadecfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_4 (Embedding)     (None, 500, 50)           4409100   \n","                                                                 \n"," gru_7 (GRU)                 (None, 50)                15300     \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 4,424,451\n","Trainable params: 4,424,451\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/5\n","547/547 [==============================] - 78s 140ms/step - loss: 0.5365 - accuracy: 0.7171\n","Epoch 2/5\n","547/547 [==============================] - 77s 140ms/step - loss: 0.2720 - accuracy: 0.8893\n","Epoch 3/5\n","547/547 [==============================] - 77s 140ms/step - loss: 0.1542 - accuracy: 0.9462\n","Epoch 4/5\n","547/547 [==============================] - 76s 140ms/step - loss: 0.0698 - accuracy: 0.9778\n","Epoch 5/5\n","547/547 [==============================] - 78s 143ms/step - loss: 0.0289 - accuracy: 0.9919\n","Test accuracy: 0.8782666921615601\n"]}],"source":["from keras import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n","\n","embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=max_words, weights=[emb_matrix], trainable=True)\n","\n","embedding_size=32\n","model=Sequential()\n","model.add(embedding_layer)\n","model.add(GRU(units=50, input_shape=(X_train.shape[1],1), activation='tanh'))\n","#model.add(LSTM(100))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', \n","             optimizer='adam', \n","             metrics=['accuracy'])\n","print(model.summary())\n","\n","batch_size=32\n","model.fit(X_train, y_train, epochs = 5, batch_size=batch_size, verbose = 'auto')\n","\n","scores = model.evaluate(X_val, y_val, verbose=0)\n","print('Test accuracy:', scores[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":334225,"status":"ok","timestamp":1648650037400,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"7hTFT9AWLfxH","outputId":"040c25d6-babe-43b7-8118-0a2748999cca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_5 (Embedding)     (None, 500, 50)           4409100   \n","                                                                 \n"," gru_8 (GRU)                 (None, 50)                15300     \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 4,424,451\n","Trainable params: 15,351\n","Non-trainable params: 4,409,100\n","_________________________________________________________________\n","None\n","Epoch 1/5\n","547/547 [==============================] - 68s 118ms/step - loss: 0.5859 - accuracy: 0.6735\n","Epoch 2/5\n","547/547 [==============================] - 64s 117ms/step - loss: 0.4146 - accuracy: 0.8137\n","Epoch 3/5\n","547/547 [==============================] - 65s 119ms/step - loss: 0.3698 - accuracy: 0.8413\n","Epoch 4/5\n","547/547 [==============================] - 65s 118ms/step - loss: 0.3407 - accuracy: 0.8557\n","Epoch 5/5\n","547/547 [==============================] - 65s 120ms/step - loss: 0.3229 - accuracy: 0.8635\n","Test accuracy: 0.8422666788101196\n"]}],"source":["from keras import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n","\n","embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=max_words, weights=[emb_matrix], trainable=False)\n","\n","embedding_size=32\n","model=Sequential()\n","model.add(embedding_layer)\n","model.add(GRU(units=50, input_shape=(X_train.shape[1],1), activation='tanh'))\n","#model.add(LSTM(100))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', \n","             optimizer='adam', \n","             metrics=['accuracy'])\n","print(model.summary())\n","\n","batch_size=32\n","model.fit(X_train, y_train, epochs = 5, batch_size=batch_size, verbose = 'auto')\n","\n","scores = model.evaluate(X_val, y_val, verbose=0)\n","print('Test accuracy:', scores[1])"]},{"cell_type":"markdown","metadata":{"id":"jJY7Zr4VN2BP"},"source":["# Testing Data"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1648885331546,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"5_MLqoghN4Ac","outputId":"608e3152-7a3e-4208-e8a3-f8e5a19022ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 500, 50)           4409100   \n","                                                                 \n"," gru_2 (GRU)                 (None, 500, 50)           15300     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 500, 50)           0         \n","                                                                 \n"," gru_3 (GRU)                 (None, 50)                15300     \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 4,439,751\n","Trainable params: 4,439,751\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["from keras import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n","\n","embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=max_words, weights=[emb_matrix], trainable=True)\n","\n","embedding_size=32\n","model=Sequential()\n","model.add(embedding_layer)\n","model.add(GRU(units=50, return_sequences = True, input_shape=(dataset.shape[1],1), activation='tanh'))\n","#model.add(LSTM(100))\n","model.add(Dropout(0.6))\n","model.add(GRU(units=50, input_shape=(dataset.shape[1],1), activation='tanh'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', \n","             optimizer='adam', \n","             metrics=['accuracy'])\n","print(model.summary())"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1022461,"status":"ok","timestamp":1648886356370,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"7delzupfN8oN","outputId":"023150da-063d-436a-96c3-2576ffbf49e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","782/782 [==============================] - 208s 263ms/step - loss: 0.4791 - accuracy: 0.7587\n","Epoch 2/5\n","782/782 [==============================] - 203s 259ms/step - loss: 0.2394 - accuracy: 0.9064\n","Epoch 3/5\n","782/782 [==============================] - 205s 262ms/step - loss: 0.1367 - accuracy: 0.9517\n","Epoch 4/5\n","782/782 [==============================] - 203s 260ms/step - loss: 0.0673 - accuracy: 0.9792\n","Epoch 5/5\n","782/782 [==============================] - 204s 261ms/step - loss: 0.0322 - accuracy: 0.9908\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x21714f976d0>"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["batch_size=32\n","model.fit(dataset, y, epochs = 5, batch_size=batch_size, verbose = 'auto')"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45713,"status":"ok","timestamp":1648886402363,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"SkDvJVhxN_bI","outputId":"e7224e77-8838-408a-c946-9c016c72ebdc"},"outputs":[{"data":{"text/plain":["array([[   0,    0,    0, ...,   42,  585,   12],\n","       [   0,    0,    0, ...,  293,   16,  299],\n","       [   0,    0,    0, ...,  431,   81,   55],\n","       ...,\n","       [   0,    0,    0, ...,  698,  772, 2313],\n","       [   0,    0,    0, ...,  396,   37,   58],\n","       [   0,    0,    0, ...,  710, 2189,   55]])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["test_df['tokens'] = test_df['text'].apply(tokenizeReview)\n","test_df['lemmTokens'] = test_df['tokens'].apply(lemmatizer)\n","test_df['vecLem'] = test_df['lemmTokens'].apply(convertToIndex)\n","test_x = sequence.pad_sequences(test_df['vecLem'], maxlen=max_words)\n","test_x"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84838,"status":"ok","timestamp":1648886487202,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"8DesukykOHla","outputId":"c44acc55-3ffb-44bd-c314-fbfc545e204e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.8653600215911865\n","Accuracy of prediction on test set :  0.86536\n","[[10983  1517]\n"," [ 1849 10651]]\n"]}],"source":["test_y = test_df['score']\n","scores = model.evaluate(test_x, test_y, verbose=0)\n","print('Test accuracy:', scores[1])\n","pred = model.predict(test_x)\n","from sklearn.metrics import accuracy_score\n","pred_labels = []\n","for i in pred:\n","    if i >= 0.5:\n","        pred_labels.append(1)\n","    else:\n","        pred_labels.append(0)\n","print(\"Accuracy of prediction on test set : \", accuracy_score(test_y,pred_labels))\n","\n","from sklearn.metrics import confusion_matrix\n","cm=confusion_matrix(test_y,pred_labels)\n","print(cm)\n","\n","test_df['pred'] = pred_labels\n","test_df\n","test_df.to_csv(\"test_df_pred_with_lemma__trainable_true_gru.csv\")"]},{"cell_type":"markdown","metadata":{"id":"3VMvqqyuOahx"},"source":["**trainable false**"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1648886487502,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"A5ios-gCOcuT","outputId":"ed90f91b-8339-4619-940b-26ef1c304d25"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, 500, 50)           4409100   \n","                                                                 \n"," gru_4 (GRU)                 (None, 500, 50)           15300     \n","                                                                 \n"," dropout_2 (Dropout)         (None, 500, 50)           0         \n","                                                                 \n"," gru_5 (GRU)                 (None, 50)                15300     \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 4,439,751\n","Trainable params: 30,651\n","Non-trainable params: 4,409,100\n","_________________________________________________________________\n","None\n"]}],"source":["from keras import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n","\n","embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=max_words, weights=[emb_matrix], trainable=False)\n","\n","embedding_size=32\n","model=Sequential()\n","model.add(embedding_layer)\n","model.add(GRU(units=50, return_sequences = True, input_shape=(dataset.shape[1],1), activation='tanh'))\n","#model.add(LSTM(100))\n","model.add(Dropout(0.6))\n","model.add(GRU(units=50, input_shape=(dataset.shape[1],1), activation='tanh'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', \n","             optimizer='adam', \n","             metrics=['accuracy'])\n","print(model.summary())"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":917610,"status":"ok","timestamp":1648887405113,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"YkWI4Hf_Og6W","outputId":"8f4187e9-34fb-4463-d6c3-1ab41ac75f57"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","782/782 [==============================] - 183s 232ms/step - loss: 0.5486 - accuracy: 0.7076\n","Epoch 2/5\n","782/782 [==============================] - 182s 233ms/step - loss: 0.3886 - accuracy: 0.8294\n","Epoch 3/5\n","782/782 [==============================] - 187s 239ms/step - loss: 0.3515 - accuracy: 0.8503\n","Epoch 4/5\n","782/782 [==============================] - 183s 234ms/step - loss: 0.3281 - accuracy: 0.8588\n","Epoch 5/5\n","782/782 [==============================] - 182s 233ms/step - loss: 0.3115 - accuracy: 0.8695\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2174611eca0>"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["batch_size=32\n","model.fit(dataset, y, epochs = 5, batch_size=batch_size, verbose = 'auto')"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88926,"status":"ok","timestamp":1648887494042,"user":{"displayName":"Peng Xiang Wong","userId":"12326358141916594350"},"user_tz":-480},"id":"FPxkVBLOOo0d","outputId":"24eb1980-989a-42d6-bf2a-262489192207"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.8665199875831604\n","Accuracy of prediction on test set :  0.86652\n","[[10948  1552]\n"," [ 1785 10715]]\n"]}],"source":["test_y = test_df['score']\n","scores = model.evaluate(test_x, test_y, verbose=0)\n","print('Test accuracy:', scores[1])\n","pred = model.predict(test_x)\n","from sklearn.metrics import accuracy_score\n","pred_labels = []\n","for i in pred:\n","    if i >= 0.5:\n","        pred_labels.append(1)\n","    else:\n","        pred_labels.append(0)\n","print(\"Accuracy of prediction on test set : \", accuracy_score(test_y,pred_labels))\n","\n","from sklearn.metrics import confusion_matrix\n","cm=confusion_matrix(test_y,pred_labels)\n","print(cm)\n","\n","test_df['pred'] = pred_labels\n","test_df\n","test_df.to_csv(\"test_df_pred_with_lemma__trainable_false_gru.csv\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO0mAXx11l+wnO+FkzPfgKN","collapsed_sections":[],"name":"Preprocessing (Lemma) Project RNN.ipynb","provenance":[{"file_id":"1pACWI9fSeOmbNSDecF2wlfG8d-h_Xjiu","timestamp":1648642640226},{"file_id":"1_f05GZgigKCkYbIW7GvNH0YCSXaLNkVg","timestamp":1648552995953}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
